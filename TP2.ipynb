{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a\n",
    "\n",
    "# obtain the headers\n",
    "with open('wine.csv', 'r') as file:\n",
    "    headers = file.readline().split(',')\n",
    "\n",
    "# read the data from the csv file\n",
    "data = np.genfromtxt('wine.csv', delimiter=',')\n",
    "\n",
    "# drop the text headers and keep only the values\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 14)\n",
      "[1.42e+01 1.76e+00 2.45e+00 1.52e+01 1.12e+02 3.27e+00 3.39e+00 3.40e-01\n",
      " 1.97e+00 6.75e+00 1.05e+00 2.85e+00 1.45e+03 1.00e+00]\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "### b\n",
    "\n",
    "# get the independant variables\n",
    "x = data[:, :-1]\n",
    "\n",
    "# get the single dependant variable\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### c\n",
    "\n",
    "# obtain the mean vector of data\n",
    "def get_mean_vector(x):\n",
    "    return np.mean(x, axis=0)\n",
    "\n",
    "# obtain the standard deviation vector of data\n",
    "def get_std_vector(x):\n",
    "    rows_qty = x.shape[0]\n",
    "    col_qty = x.shape[1]\n",
    "    ret = np.zeros(col_qty)\n",
    "\n",
    "    mean = get_mean_vector(x)\n",
    "\n",
    "    for i in range(rows_qty):\n",
    "        ret = ret + (x[i] - mean) ** 2\n",
    "\n",
    "    return ret / (rows_qty - 1)\n",
    "\n",
    "# obtain the normalized vector of data\n",
    "def get_normailized(x):\n",
    "    return (x - get_mean_vector(x)) / get_std_vector(x)\n",
    "\n",
    "x = get_normailized(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### d\n",
    "\n",
    "cov = np.cov(x, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "### e\n",
    "\n",
    "def get_max_eigenvector(matrix, iter = 20):\n",
    "    # start with a random vector\n",
    "    ret = np.random.rand(matrix.shape[1])\n",
    "\n",
    "    # apply the power method, simply multiplying the matrix with the vector and dividing by the norm\n",
    "    for _ in range(iter):\n",
    "        next = np.dot(matrix, ret)\n",
    "        ret = next / np.linalg.norm(next)\n",
    "    return ret\n",
    "\n",
    "# obtain the eigenvalue simply by calculating using the formula see in class\n",
    "def get_related_eigenvalue(matrix, max_eigenvector):\n",
    "    t_max_eigenvector = np.transpose(max_eigenvector)\n",
    "    return np.dot(t_max_eigenvector, np.dot(matrix, max_eigenvector)) / (np.dot(t_max_eigenvector, max_eigenvector))\n",
    "\n",
    "max_cov_eigenvector = get_max_eigenvector(cov)\n",
    "max_cov_eigenvalue = get_related_eigenvalue(cov, max_cov_eigenvector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### f\n",
    "\n",
    "def get_max_eigenvectors(matrix, qty = 1, iter = 200):\n",
    "    \n",
    "    eigenvectors = np.zeros(shape=(qty, matrix.shape[1]))\n",
    "\n",
    "    for i in range(qty):\n",
    "        aux = np.random.rand(matrix.shape[1])\n",
    "\n",
    "        # for the next iteration start with a random vector and remove the components of already calculed eigenvectors\n",
    "        for _ in range(iter):\n",
    "            for eigenvector in eigenvectors:\n",
    "                aux = aux - np.dot(eigenvector, aux) * eigenvector\n",
    "            next_aux = np.dot(matrix, aux)\n",
    "            aux = next_aux / np.linalg.norm(next_aux)\n",
    "\n",
    "        eigenvectors[i] = aux\n",
    "\n",
    "    return eigenvectors\n",
    "\n",
    "def get_max_eigenvalues(matrix, eigenvectors):\n",
    "    eigenvalues = np.zeros(eigenvectors.shape[0])\n",
    "\n",
    "    i = 0\n",
    "    for eigenvector in eigenvectors:\n",
    "        eigenvalues[i] = get_related_eigenvalue(matrix, eigenvector)\n",
    "        i = i + 1\n",
    "        \n",
    "    return eigenvalues\n",
    "\n",
    "eigenvectors = get_max_eigenvectors(cov, cov.shape[0])\n",
    "eigenvalues = np.array(get_max_eigenvalues(cov, eigenvectors))\n",
    "\n",
    "# print(np.allclose(np.linalg.eig(cov).eigenvalues, eigenvalues, rtol=1e-03))\n",
    "# print(np.allclose(np.transpose(np.linalg.eig(cov).eigenvectors  ** 2), eigenvectors  ** 2, rtol=1e-03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", actual is: 1.0prediction is: 1.0\n",
      ", actual is: 1.0prediction is: 1.0\n",
      ", actual is: 1.0prediction is: 1.0\n",
      ", actual is: 1.0prediction is: 1.0\n",
      ", actual is: 1.0prediction is: 1.0\n",
      ", actual is: 1.0prediction is: 1.0\n",
      ", actual is: 2.0prediction is: 2.0\n",
      ", actual is: 2.0prediction is: 2.0\n",
      ", actual is: 2.0prediction is: 2.0\n",
      ", actual is: 2.0prediction is: 2.0\n",
      ", actual is: 2.0prediction is: 2.0\n",
      ", actual is: 2.0prediction is: 2.0\n",
      ", actual is: 2.0prediction is: 1.0\n",
      ", actual is: 3.0prediction is: 3.0\n",
      ", actual is: 3.0prediction is: 3.0\n",
      ", actual is: 3.0prediction is: 3.0\n",
      ", actual is: 3.0prediction is: 3.0\n",
      ", actual is: 3.0prediction is: 3.0\n"
     ]
    }
   ],
   "source": [
    "### g\n",
    "\n",
    "# predict the result label of the input array containing the samples atributes and needs the eigenvectors of the covariance matrix\n",
    "def predict_data(input, eigenvectors):\n",
    "\n",
    "    # transform the data into the new basis using the eigenvectors\n",
    "    transformed_x = np.dot(x, np.transpose(eigenvectors))\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    # fit the transformed data in to the KNN model\n",
    "    knn.fit(transformed_x, y)\n",
    "\n",
    "    # predit the result transforming the input data into the new basis and then using the knn model\n",
    "    return knn.predict(np.dot(input, np.transpose(eigenvectors)))\n",
    "\n",
    "# take all the samples of the data which their index is divisible by 10 for testing the model\n",
    "test = x[::10]\n",
    "correct_labels = y[::10]\n",
    "predicted_data = predict_data(test, eigenvectors)\n",
    "\n",
    "for i in range(len(predicted_data)):\n",
    "    print (\", actual is: \" + str(correct_labels[i]) + \"prediction is: \" + str(predicted_data[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(0.6111111111111112, 0.6391973009097871, 63.91973009097871, 0.6391973009097871)\n",
      "2\n",
      "(0.75, 0.17048331542044542, 17.048331542044544, 0.8096806163302325)\n",
      "3\n",
      "(0.8333333333333334, 0.12202397400868929, 12.202397400868929, 0.9317045903389217)\n",
      "4\n",
      "(0.8888888888888888, 0.03255070436982658, 3.255070436982658, 0.9642552947087484)\n"
     ]
    }
   ],
   "source": [
    "### a\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# predict the result label of the input array containing the samples atributes and needs the eigenvectors of the covariance matrix\n",
    "def benchmark(x, y, eigenvectors, eigenvalues):\n",
    "\n",
    "    # make a shuffled training and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=11)\n",
    "    \n",
    "    #transform the training data into the new basis using the eigenvectors\n",
    "    transformed_x_train = np.dot(x_train, np.transpose(eigenvectors))\n",
    "\n",
    "    # for the case when only use the first principal component \n",
    "    # if the training data is a vector, transform it into a matrix with one column\n",
    "    if (transformed_x_train.shape == (transformed_x_train.shape[0],)):\n",
    "        transformed_x_train = transformed_x_train.reshape(-1, 1)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    # fit the transformed data in to the KNN model\n",
    "    knn.fit(transformed_x_train, y_train)\n",
    "\n",
    "    #transform the training data into the new basis using the eigenvectors\n",
    "    transformed_x_test = np.dot(x_test, np.transpose(eigenvectors))\n",
    "\n",
    "    # for the case when only use the first principal component \n",
    "    # if the training data is a vector, transform it into a matrix with one column\n",
    "    if (transformed_x_test.shape == (transformed_x_test.shape[0],)):\n",
    "        transformed_x_test = transformed_x_test.reshape(-1, 1)\n",
    "\n",
    "    # predit the result transforming the test data into the new basis and then using the knn model\n",
    "    predicted_y = knn.predict(transformed_x_test)\n",
    "\n",
    "    # calculate the accuracy\n",
    "    accuracy = np.sum(predicted_y == y_test) / len(y_test)\n",
    "\n",
    "    print(transformed_x_train.shape[1])\n",
    "\n",
    "    explain_varianze = eigenvalues[transformed_x_train.shape[1] - 1] / np.sum(eigenvalues)\n",
    "    percen_explain_varianze = 100 * explain_varianze\n",
    "    accumulated_explain_varianze = np.sum(eigenvalues[0:transformed_x_train.shape[1]]) / np.sum(eigenvalues)\n",
    "\n",
    "    return accuracy, explain_varianze, percen_explain_varianze, accumulated_explain_varianze\n",
    "\n",
    "print(benchmark(x, y, eigenvectors[0, :], eigenvalues))\n",
    "print(benchmark(x, y, eigenvectors[[0,1], :], eigenvalues))\n",
    "print(benchmark(x, y, eigenvectors[[0,1,2], :], eigenvalues))\n",
    "print(benchmark(x, y, eigenvectors[[0,1,2,3], :], eigenvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
